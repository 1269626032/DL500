\contentsline {chapter}{\tocchapter {Chapter}{1}{数学基础}}{1}{chapter.1}
\contentsline {section}{\tocsection {}{1}{向量和矩阵}}{1}{section.1.1}
\contentsline {subsection}{\tocsubsection {}{1.1}{标量、向量、矩阵、张量之间的联系}}{1}{subsection.1.1.1}
\contentsline {subsubsection}{\tocsubsubsection {}{1.1.1}{标量}}{1}{subsubsection.1.1.1.1}
\contentsline {subsubsection}{\tocsubsubsection {}{1.1.2}{向量}}{1}{subsubsection.1.1.1.2}
\contentsline {subsubsection}{\tocsubsubsection {}{1.1.3}{矩阵}}{1}{subsubsection.1.1.1.3}
\contentsline {subsubsection}{\tocsubsubsection {}{1.1.4}{张量}}{2}{subsubsection.1.1.1.4}
\contentsline {subsubsection}{\tocsubsubsection {}{1.1.5}{四者之间关系}}{2}{subsubsection.1.1.1.5}
\contentsline {subsection}{\tocsubsection {}{1.2}{张量与矩阵的区别}}{2}{subsection.1.1.2}
\contentsline {subsection}{\tocsubsection {}{1.3}{矩阵和向量相乘结果}}{2}{subsection.1.1.3}
\contentsline {subsection}{\tocsubsection {}{1.4}{向量和矩阵的范数归纳}}{2}{subsection.1.1.4}
\contentsline {subsubsection}{\tocsubsubsection {}{1.4.1}{向量的范数}}{3}{subsubsection.1.1.4.1}
\contentsline {subsubsection}{\tocsubsubsection {}{1.4.2}{矩阵的范数}}{4}{subsubsection.1.1.4.2}
\contentsline {subsection}{\tocsubsection {}{1.5}{如何判断一个矩阵为正定}}{5}{subsection.1.1.5}
\contentsline {section}{\tocsection {}{2}{导数和偏导数}}{5}{section.1.2}
\contentsline {subsection}{\tocsubsection {}{2.1}{导数偏导计算}}{5}{subsection.1.2.1}
\contentsline {subsubsection}{\tocsubsubsection {}{2.1.1}{导数定义}}{5}{subsubsection.1.2.1.1}
\contentsline {subsubsection}{\tocsubsubsection {}{2.1.2}{偏导数}}{6}{subsubsection.1.2.1.2}
\contentsline {subsection}{\tocsubsection {}{2.2}{导数和偏导数有什么区别？}}{6}{subsection.1.2.2}
\contentsline {section}{\tocsection {}{3}{特征值和特征向量}}{7}{section.1.3}
\contentsline {subsection}{\tocsubsection {}{3.1}{特征值分解与特征向量}}{7}{subsection.1.3.1}
\contentsline {subsection}{\tocsubsection {}{3.2}{奇异值与特征值有什么关系}}{7}{subsection.1.3.2}
\contentsline {section}{\tocsection {}{4}{概率分布与随机变量}}{8}{section.1.4}
\contentsline {subsection}{\tocsubsection {}{4.1}{机器学习为什么要使用概率}}{8}{subsection.1.4.1}
\contentsline {subsection}{\tocsubsection {}{4.2}{变量与随机变量有什么区别}}{8}{subsection.1.4.2}
\contentsline {subsubsection}{\tocsubsubsection {}{4.2.1}{随机变量}}{8}{subsubsection.1.4.2.1}
\contentsline {subsubsection}{\tocsubsubsection {}{4.2.2}{变量与随机变量的区别}}{8}{subsubsection.1.4.2.2}
\contentsline {subsection}{\tocsubsection {}{4.3}{随机变量与概率分布的联系}}{9}{subsection.1.4.3}
\contentsline {subsection}{\tocsubsection {}{4.4}{离散型随机变量和概率质量函数}}{9}{subsection.1.4.4}
\contentsline {subsection}{\tocsubsection {}{4.5}{连续型随机变量和概率密度函数}}{9}{subsection.1.4.5}
\contentsline {subsection}{\tocsubsection {}{4.6}{举例理解条件概率}}{10}{subsection.1.4.6}
\contentsline {subsection}{\tocsubsection {}{4.7}{联合概率与边缘概率联系区别}}{11}{subsection.1.4.7}
\contentsline {subsubsection}{\tocsubsubsection {}{4.7.1}{区别}}{11}{subsubsection.1.4.7.1}
\contentsline {subsubsection}{\tocsubsubsection {}{4.7.2}{联系}}{11}{subsubsection.1.4.7.2}
\contentsline {subsection}{\tocsubsection {}{4.8}{条件概率的链式法则}}{11}{subsection.1.4.8}
\contentsline {subsection}{\tocsubsection {}{4.9}{独立性和条件独立性}}{11}{subsection.1.4.9}
\contentsline {subsubsection}{\tocsubsubsection {}{4.9.1}{独立性}}{11}{subsubsection.1.4.9.1}
\contentsline {subsubsection}{\tocsubsubsection {}{4.9.2}{条件独立性}}{12}{subsubsection.1.4.9.2}
\contentsline {section}{\tocsection {}{5}{常见概率分布}}{12}{section.1.5}
\contentsline {subsection}{\tocsubsection {}{5.1}{ Bernoulli分布}}{12}{subsection.1.5.1}
\contentsline {subsection}{\tocsubsection {}{5.2}{Multinoulli分布}}{12}{subsection.1.5.2}
\contentsline {subsection}{\tocsubsection {}{5.3}{二项分布}}{12}{subsection.1.5.3}
\contentsline {subsection}{\tocsubsection {}{5.4}{多项式分布}}{13}{subsection.1.5.4}
\contentsline {subsection}{\tocsubsection {}{5.5}{ 高斯分布}}{13}{subsection.1.5.5}
\contentsline {subsection}{\tocsubsection {}{5.6}{ 指数分布}}{14}{subsection.1.5.6}
\contentsline {subsection}{\tocsubsection {}{5.7}{ Laplace分布（拉普拉斯分布）}}{14}{subsection.1.5.7}
\contentsline {subsection}{\tocsubsection {}{5.8}{Dirac分布和经验分布}}{14}{subsection.1.5.8}
\contentsline {section}{\tocsection {}{6}{期望、方差、协方差、相关系数}}{14}{section.1.6}
\contentsline {subsection}{\tocsubsection {}{6.1}{ 期望}}{14}{subsection.1.6.1}
\contentsline {subsubsection}{\tocsubsubsection {}{6.1.1}{线性运算}}{14}{subsubsection.1.6.1.1}
\contentsline {subsubsection}{\tocsubsubsection {}{6.1.2}{ 推广形式}}{14}{subsubsection.1.6.1.2}
\contentsline {subsubsection}{\tocsubsubsection {}{6.1.3}{函数期望}}{15}{subsubsection.1.6.1.3}
\contentsline {subsection}{\tocsubsection {}{6.2}{方差}}{15}{subsection.1.6.2}
\contentsline {subsection}{\tocsubsection {}{6.3}{ 协方差}}{15}{subsection.1.6.3}
\contentsline {subsection}{\tocsubsection {}{6.4}{ 相关系数}}{16}{subsection.1.6.4}
\contentsline {chapter}{\tocchapter {Chapter}{2}{机器学习基础}}{17}{chapter.2}
\contentsline {section}{\tocsection {}{1}{ 基本概念}}{17}{section.2.1}
\contentsline {subsection}{\tocsubsection {}{1.1}{大话理解机器学习本质}}{17}{subsection.2.1.1}
\contentsline {subsection}{\tocsubsection {}{1.2}{什么是神经网络}}{17}{subsection.2.1.2}
\contentsline {subsection}{\tocsubsection {}{1.3}{各种常见算法图示}}{18}{subsection.2.1.3}
\contentsline {subsection}{\tocsubsection {}{1.4}{计算图的导数计算}}{18}{subsection.2.1.4}
\contentsline {subsection}{\tocsubsection {}{1.5}{理解局部最优与全局最优}}{18}{subsection.2.1.5}
\contentsline {subsection}{\tocsubsection {}{1.6}{大数据与深度学习之间的关系}}{19}{subsection.2.1.6}
\contentsline {section}{\tocsection {}{2}{机器学习学习方式}}{19}{section.2.2}
\contentsline {subsection}{\tocsubsection {}{2.1}{ 监督学习}}{19}{subsection.2.2.1}
\contentsline {subsection}{\tocsubsection {}{2.2}{非监督式学习}}{19}{subsection.2.2.2}
\contentsline {subsection}{\tocsubsection {}{2.3}{半监督式学习}}{20}{subsection.2.2.3}
\contentsline {subsection}{\tocsubsection {}{2.4}{弱监督学习}}{20}{subsection.2.2.4}
\contentsline {subsection}{\tocsubsection {}{2.5}{监督学习有哪些步骤}}{20}{subsection.2.2.5}
\contentsline {section}{\tocsection {}{3}{ 分类算法}}{21}{section.2.3}
\contentsline {subsection}{\tocsubsection {}{3.1}{常用分类算法的优缺点？}}{21}{subsection.2.3.1}
\contentsline {subsection}{\tocsubsection {}{3.2}{2.8.2 分类算法的评估方法}}{29}{subsection.2.3.2}
\contentsline {subsection}{\tocsubsection {}{3.3}{2.8.3 正确率能很好的评估分类算法吗}}{31}{subsection.2.3.3}
\contentsline {subsection}{\tocsubsection {}{3.4}{什么样的分类器是最好的}}{31}{subsection.2.3.4}
\contentsline {section}{\tocsection {}{4}{2.9 逻辑回归}}{31}{section.2.4}
\contentsline {subsection}{\tocsubsection {}{4.1}{2.9.1 回归划分}}{31}{subsection.2.4.1}
\contentsline {subsection}{\tocsubsection {}{4.2}{逻辑回归适用性}}{31}{subsection.2.4.2}
\contentsline {subsection}{\tocsubsection {}{4.3}{生成模型和判别模型的区别}}{32}{subsection.2.4.3}
\contentsline {subsection}{\tocsubsection {}{4.4}{逻辑回归与朴素贝叶斯有什么区别}}{32}{subsection.2.4.4}
\contentsline {subsection}{\tocsubsection {}{4.5}{线性回归与逻辑回归的区别}}{32}{subsection.2.4.5}
\contentsline {section}{\tocsection {}{5}{2.10 代价函数}}{33}{section.2.5}
\contentsline {subsection}{\tocsubsection {}{5.1}{2.10.1 为什么需要代价函数}}{33}{subsection.2.5.1}
\contentsline {subsection}{\tocsubsection {}{5.2}{代价函数作用原理}}{33}{subsection.2.5.2}
\contentsline {subsection}{\tocsubsection {}{5.3}{为什么代价函数要非负}}{34}{subsection.2.5.3}
\contentsline {subsection}{\tocsubsection {}{5.4}{常见代价函数}}{34}{subsection.2.5.4}
\contentsline {subsection}{\tocsubsection {}{5.5}{2.10.5 为什么用交叉熵代替二次代价函数}}{39}{subsection.2.5.5}
\contentsline {section}{\tocsection {}{6}{2.11 损失函数}}{39}{section.2.6}
\contentsline {subsection}{\tocsubsection {}{6.1}{2.11.1 什么是损失函数}}{39}{subsection.2.6.1}
\contentsline {subsection}{\tocsubsection {}{6.2}{2.11.2 常见的损失函数}}{40}{subsection.2.6.2}
\contentsline {subsection}{\tocsubsection {}{6.3}{2.11.3 逻辑回归为什么使用对数损失函数}}{41}{subsection.2.6.3}
\contentsline {subsection}{\tocsubsection {}{6.4}{对数损失函数是如何度量损失的}}{42}{subsection.2.6.4}
\contentsline {section}{\tocsection {}{7}{ 梯度下降}}{43}{section.2.7}
\contentsline {subsection}{\tocsubsection {}{7.1}{机器学习中为什么需要梯度下降}}{43}{subsection.2.7.1}
\contentsline {subsection}{\tocsubsection {}{7.2}{梯度下降法缺点}}{43}{subsection.2.7.2}
\contentsline {subsection}{\tocsubsection {}{7.3}{梯度下降法直观理解}}{43}{subsection.2.7.3}
\contentsline {subsection}{\tocsubsection {}{7.4}{梯度下降法算法描述}}{44}{subsection.2.7.4}
\contentsline {subsection}{\tocsubsection {}{7.5}{如何对梯度下降法进行调优}}{45}{subsection.2.7.5}
\contentsline {subsection}{\tocsubsection {}{7.6}{随机梯度和批量梯度区别}}{45}{subsection.2.7.6}
\contentsline {subsection}{\tocsubsection {}{7.7}{2.12.7 各种梯度下降法性能比较}}{47}{subsection.2.7.7}
\contentsline {section}{\tocsection {}{8}{2.14 线性判别分析（LDA）}}{47}{section.2.8}
\contentsline {subsection}{\tocsubsection {}{8.1}{2.14.1 LDA思想总结}}{47}{subsection.2.8.1}
\contentsline {subsection}{\tocsubsection {}{8.2}{2.14.2 图解LDA核心思想}}{48}{subsection.2.8.2}
\contentsline {subsection}{\tocsubsection {}{8.3}{2.14.3 二类LDA算法原理}}{48}{subsection.2.8.3}
\contentsline {subsection}{\tocsubsection {}{8.4}{LDA算法流程总结}}{49}{subsection.2.8.4}
\contentsline {subsection}{\tocsubsection {}{8.5}{LDA和PCA区别}}{50}{table.2.5}
\contentsline {subsection}{\tocsubsection {}{8.6}{ LDA优缺点}}{53}{table.2.6}
\contentsline {section}{\tocsection {}{9}{主成分分析（PCA）}}{53}{section.2.9}
\contentsline {subsection}{\tocsubsection {}{9.1}{主成分分析（PCA）思想总结}}{53}{subsection.2.9.1}
\contentsline {subsection}{\tocsubsection {}{9.2}{图解PCA核心思想}}{53}{subsection.2.9.2}
\contentsline {subsection}{\tocsubsection {}{9.3}{ PCA算法推理}}{53}{subsection.2.9.3}
\contentsline {subsection}{\tocsubsection {}{9.4}{PCA算法流程总结}}{55}{subsection.2.9.4}
\contentsline {subsection}{\tocsubsection {}{9.5}{PCA算法主要优缺点}}{58}{table.2.7}
\contentsline {subsection}{\tocsubsection {}{9.6}{降维的必要性及目的}}{58}{subsection.2.9.6}
\contentsline {subsection}{\tocsubsection {}{9.7}{KPCA与PCA的区别}}{58}{subsection.2.9.7}
\contentsline {section}{\tocsection {}{10}{ 模型评估}}{58}{section.2.10}
\contentsline {subsection}{\tocsubsection {}{10.1}{模型评估常用方法？}}{58}{subsection.2.10.1}
\contentsline {subsection}{\tocsubsection {}{10.2}{2.16.2 误差、偏差和方差有什么区别和联系}}{59}{subsection.2.10.2}
\contentsline {subsection}{\tocsubsection {}{10.3}{经验误差与泛化误差}}{60}{subsection.2.10.3}
\contentsline {subsection}{\tocsubsection {}{10.4}{图解欠拟合、过拟合}}{60}{subsection.2.10.4}
\contentsline {subsection}{\tocsubsection {}{10.5}{如何解决过拟合与欠拟合}}{60}{subsection.2.10.5}
\contentsline {subsection}{\tocsubsection {}{10.6}{交叉验证的主要作用}}{61}{subsection.2.10.6}
\contentsline {subsection}{\tocsubsection {}{10.7}{理解k折交叉验证}}{61}{subsection.2.10.7}
\contentsline {subsection}{\tocsubsection {}{10.8}{混淆矩阵}}{61}{subsection.2.10.8}
\contentsline {subsection}{\tocsubsection {}{10.9}{错误率及精度}}{62}{subsection.2.10.9}
\contentsline {subsection}{\tocsubsection {}{10.10}{查准率与查全率}}{62}{subsection.2.10.10}
\contentsline {subsection}{\tocsubsection {}{10.11}{ROC与AUC}}{62}{subsection.2.10.11}
\contentsline {subsection}{\tocsubsection {}{10.12}{如何画ROC曲线}}{63}{subsection.2.10.12}
\contentsline {subsection}{\tocsubsection {}{10.13}{如何计算TPR，FPR}}{63}{subsection.2.10.13}
\contentsline {subsection}{\tocsubsection {}{10.14}{如何计算AUC}}{64}{subsection.2.10.14}
\contentsline {subsection}{\tocsubsection {}{10.15}{为什么使用Roc和Auc评价分类器}}{65}{subsection.2.10.15}
\contentsline {subsection}{\tocsubsection {}{10.16}{直观理解AUC}}{65}{subsection.2.10.16}
\contentsline {subsection}{\tocsubsection {}{10.17}{代价敏感错误率与代价曲线}}{65}{subsection.2.10.17}
\contentsline {subsection}{\tocsubsection {}{10.18}{模型有哪些比较检验方法}}{66}{subsection.2.10.18}
\contentsline {subsection}{\tocsubsection {}{10.19}{为什么使用标准差}}{66}{subsection.2.10.19}
\contentsline {subsection}{\tocsubsection {}{10.20}{类别不平衡产生原因}}{66}{subsection.2.10.20}
\contentsline {section}{\tocsection {}{11}{决策树}}{68}{section.2.11}
\contentsline {subsection}{\tocsubsection {}{11.1}{决策树的基本原理}}{68}{subsection.2.11.1}
\contentsline {subsection}{\tocsubsection {}{11.2}{决策树的三要素？}}{68}{subsection.2.11.2}
\contentsline {subsection}{\tocsubsection {}{11.3}{决策树学习基本算法}}{68}{subsection.2.11.3}
\contentsline {subsection}{\tocsubsection {}{11.4}{决策树算法优缺点}}{68}{subsection.2.11.4}
\contentsline {subsection}{\tocsubsection {}{11.5}{熵的概念以及理解}}{69}{subsection.2.11.5}
\contentsline {subsection}{\tocsubsection {}{11.6}{信息增益的理解}}{69}{subsection.2.11.6}
\contentsline {subsection}{\tocsubsection {}{11.7}{剪枝处理的作用及策略}}{69}{subsection.2.11.7}
\contentsline {section}{\tocsection {}{12}{ 支持向量机}}{70}{section.2.12}
\contentsline {subsection}{\tocsubsection {}{12.1}{什么是支持向量机}}{70}{subsection.2.12.1}
\contentsline {subsection}{\tocsubsection {}{12.2}{支持向量机能解决哪些问题}}{70}{subsection.2.12.2}
\contentsline {subsection}{\tocsubsection {}{12.3}{核函数特点及其作用}}{70}{subsection.2.12.3}
\contentsline {subsection}{\tocsubsection {}{12.4}{SVM为什么引入对偶问题}}{71}{subsection.2.12.4}
\contentsline {subsection}{\tocsubsection {}{12.5}{如何理解SVM中的对偶问题}}{71}{subsection.2.12.5}
\contentsline {subsection}{\tocsubsection {}{12.6}{常见的核函数有哪些}}{73}{table.2.17}
\contentsline {subsection}{\tocsubsection {}{12.7}{ SVM主要特点}}{73}{subsection.2.12.7}
\contentsline {subsection}{\tocsubsection {}{12.8}{ SVM主要缺点}}{74}{subsection.2.12.8}
\contentsline {subsection}{\tocsubsection {}{12.9}{逻辑回归与SVM的异同}}{74}{subsection.2.12.9}
\contentsline {section}{\tocsection {}{13}{贝叶斯分类器}}{75}{section.2.13}
\contentsline {subsection}{\tocsubsection {}{13.1}{图解极大似然估计}}{75}{subsection.2.13.1}
\contentsline {subsection}{\tocsubsection {}{13.2}{极大似然估计原理}}{76}{subsection.2.13.2}
\contentsline {subsection}{\tocsubsection {}{13.3}{贝叶斯分类器基本原理}}{76}{subsection.2.13.3}
\contentsline {subsection}{\tocsubsection {}{13.4}{朴素贝叶斯分类器}}{77}{subsection.2.13.4}
\contentsline {subsection}{\tocsubsection {}{13.5}{举例理解朴素贝叶斯分类器}}{77}{subsection.2.13.5}
\contentsline {subsection}{\tocsubsection {}{13.6}{半朴素贝叶斯分类器}}{80}{subsection.2.13.6}
\contentsline {section}{\tocsection {}{14}{ EM算法}}{80}{section.2.14}
\contentsline {subsection}{\tocsubsection {}{14.1}{EM算法基本思想}}{80}{subsection.2.14.1}
\contentsline {subsection}{\tocsubsection {}{14.2}{EM算法推导}}{80}{subsection.2.14.2}
\contentsline {subsection}{\tocsubsection {}{14.3}{ 图解EM算法}}{81}{subsection.2.14.3}
\contentsline {subsection}{\tocsubsection {}{14.4}{ EM算法流程}}{82}{subsection.2.14.4}
\contentsline {section}{\tocsection {}{15}{ 降维和聚类}}{82}{section.2.15}
\contentsline {subsection}{\tocsubsection {}{15.1}{图解为什么会产生维数灾难}}{82}{subsection.2.15.1}
\contentsline {subsection}{\tocsubsection {}{15.2}{怎样避免维数灾难}}{84}{subsection.2.15.2}
\contentsline {subsection}{\tocsubsection {}{15.3}{聚类和降维有什么区别与联系}}{84}{subsection.2.15.3}
\contentsline {subsection}{\tocsubsection {}{15.4}{有哪些聚类算法优劣衡量标准}}{84}{subsection.2.15.4}
\contentsline {subsection}{\tocsubsection {}{15.5}{聚类和分类有什么区别}}{84}{subsection.2.15.5}
\contentsline {subsection}{\tocsubsection {}{15.6}{不同聚类算法特点性能比较}}{85}{table.2.20}
\contentsline {subsection}{\tocsubsection {}{15.7}{四种常用聚类方法之比较}}{85}{subsection.2.15.7}
\contentsline {subsection}{\tocsubsection {}{15.8}{k-means聚类算法}}{85}{subsection.2.15.8}
\contentsline {subsection}{\tocsubsection {}{15.9}{层次聚类算法}}{86}{subsection.2.15.9}
\contentsline {subsection}{\tocsubsection {}{15.10}{SOM聚类算法}}{86}{subsection.2.15.10}
\contentsline {subsection}{\tocsubsection {}{15.11}{ FCM聚类算法}}{86}{subsection.2.15.11}
\contentsline {subsection}{\tocsubsection {}{15.12}{四种聚类算法试验}}{87}{subsection.2.15.12}
\contentsline {chapter}{\tocchapter {Chapter}{3}{深度学习基础}}{89}{chapter.3}
\contentsline {section}{\tocsection {}{1}{基本概念}}{89}{section.3.1}
\contentsline {subsection}{\tocsubsection {}{1.1}{神经网络组成？}}{89}{subsection.3.1.1}
\contentsline {subsection}{\tocsubsection {}{1.2}{神经网络有哪些常用模型结构？}}{90}{subsection.3.1.2}
\contentsline {subsection}{\tocsubsection {}{1.3}{如何选择深度学习开发平台？}}{90}{subsection.3.1.3}
\contentsline {subsection}{\tocsubsection {}{1.4}{为什么使用深层表示?}}{90}{subsection.3.1.4}
\contentsline {subsection}{\tocsubsection {}{1.5}{为什么深层神经网络难以训练？}}{91}{subsection.3.1.5}
\contentsline {subsection}{\tocsubsection {}{1.6}{深度学习和机器学习有什么不同？}}{91}{subsection.3.1.6}
\contentsline {section}{\tocsection {}{2}{网络操作与计算}}{91}{section.3.2}
\contentsline {subsection}{\tocsubsection {}{2.1}{前向传播与反向传播？}}{91}{subsection.3.2.1}
\contentsline {subsection}{\tocsubsection {}{2.2}{如何计算神经网络的输出？}}{92}{subsection.3.2.2}
\contentsline {subsection}{\tocsubsection {}{2.3}{如何计算卷积神经网络输出值？}}{93}{subsection.3.2.3}
\contentsline {section}{\tocsection {}{3}{ 超参数}}{93}{section.3.3}
\contentsline {subsection}{\tocsubsection {}{3.1}{什么是超参数？}}{93}{subsection.3.3.1}
\contentsline {subsection}{\tocsubsection {}{3.2}{如何寻找超参数的最优值？}}{93}{subsection.3.3.2}
\contentsline {subsection}{\tocsubsection {}{3.3}{超参数搜索一般过程？}}{94}{subsection.3.3.3}
\contentsline {section}{\tocsection {}{4}{ 激活函数}}{94}{section.3.4}
\contentsline {subsection}{\tocsubsection {}{4.1}{为什么需要非线性激活函数？}}{94}{subsection.3.4.1}
\contentsline {subsection}{\tocsubsection {}{4.2}{常见的激活函数及图像}}{94}{subsection.3.4.2}
\contentsline {subsection}{\tocsubsection {}{4.3}{3.4.3 常见激活函数的导数计算？}}{95}{subsection.3.4.3}
\contentsline {subsection}{\tocsubsection {}{4.4}{激活函数有哪些性质？}}{95}{subsection.3.4.4}
\contentsline {subsection}{\tocsubsection {}{4.5}{如何选择激活函数？}}{96}{subsection.3.4.5}
\contentsline {subsection}{\tocsubsection {}{4.6}{ 使用 ReLu激活函数的优点？}}{96}{subsection.3.4.6}
\contentsline {subsection}{\tocsubsection {}{4.7}{3.4.7 什么时候可以用线性激活函数？}}{96}{subsection.3.4.7}
\contentsline {subsection}{\tocsubsection {}{4.8}{3.4.8 怎样理解 Relu（\textless {} 0 时）是非线性激活函数？}}{96}{subsection.3.4.8}
\contentsline {subsection}{\tocsubsection {}{4.9}{3.4.9 Softmax 定义及作用}}{97}{subsection.3.4.9}
\contentsline {subsection}{\tocsubsection {}{4.10}{3.4.10 Softmax 函数如何应用于多分类？}}{97}{subsection.3.4.10}
\contentsline {subsection}{\tocsubsection {}{4.11}{3.4.11 交叉熵代价函数定义及其求导推导}}{98}{subsection.3.4.11}
\contentsline {subsection}{\tocsubsection {}{4.12}{3.4.12 为什么Tanh收敛速度比Sigmoid快？}}{99}{subsection.3.4.12}
\contentsline {subsection}{\tocsubsection {}{4.13}{3.4.12 内聚外斥 - Center Loss}}{99}{subsection.3.4.13}
\contentsline {section}{\tocsection {}{5}{3.5 Batch\_Size}}{100}{section.3.5}
\contentsline {subsection}{\tocsubsection {}{5.1}{3.5.1 为什么需要 Batch\_Size？}}{100}{subsection.3.5.1}
\contentsline {subsection}{\tocsubsection {}{5.2}{3.5.2 Batch\_Size 值的选择}}{100}{subsection.3.5.2}
\contentsline {subsection}{\tocsubsection {}{5.3}{3.5.3 在合理范围内，增大Batch\_Size有何好处？}}{101}{subsection.3.5.3}
\contentsline {subsection}{\tocsubsection {}{5.4}{3.5.4 盲目增大 Batch\_Size 有何坏处？}}{101}{subsection.3.5.4}
\contentsline {subsection}{\tocsubsection {}{5.5}{3.5.5 调节 Batch\_Size 对训练效果影响到底如何？}}{101}{subsection.3.5.5}
\contentsline {section}{\tocsection {}{6}{3.6 归一化}}{101}{section.3.6}
\contentsline {subsection}{\tocsubsection {}{6.1}{3.6.1 归一化含义？}}{101}{subsection.3.6.1}
\contentsline {subsection}{\tocsubsection {}{6.2}{3.6.2 为什么要归一化？}}{102}{subsection.3.6.2}
\contentsline {subsection}{\tocsubsection {}{6.3}{3.6.3 为什么归一化能提高求解最优解速度？}}{102}{subsection.3.6.3}
\contentsline {subsection}{\tocsubsection {}{6.4}{3.6.4 3D 图解未归一化}}{102}{subsection.3.6.4}
\contentsline {subsection}{\tocsubsection {}{6.5}{3.6.5 归一化有哪些类型？}}{102}{subsection.3.6.5}
\contentsline {subsection}{\tocsubsection {}{6.6}{3.6.6 局部响应归一化作用}}{103}{subsection.3.6.6}
\contentsline {subsection}{\tocsubsection {}{6.7}{3.6.7 理解局部响应归一化}}{103}{subsection.3.6.7}
\contentsline {subsection}{\tocsubsection {}{6.8}{3.6.8 什么是批归一化（Batch Normalization）}}{104}{subsection.3.6.8}
\contentsline {subsection}{\tocsubsection {}{6.9}{3.6.9 批归一化（BN）算法的优点}}{104}{subsection.3.6.9}
\contentsline {subsection}{\tocsubsection {}{6.10}{3.6.10 批归一化（BN）算法流程}}{104}{subsection.3.6.10}
\contentsline {subsection}{\tocsubsection {}{6.12}{3.6.12 Weight Normalization和Batch Normalization比较}}{105}{subsection.3.6.12}
\contentsline {subsection}{\tocsubsection {}{6.13}{3.6.13 Batch Normalization在什么时候用比较合适？}}{106}{subsection.3.6.13}
\contentsline {section}{\tocsection {}{7}{3.7 预训练与微调(fine tuning)}}{106}{section.3.7}
\contentsline {subsection}{\tocsubsection {}{7.1}{3.7.1 为什么无监督预训练可以帮助深度学习？}}{106}{subsection.3.7.1}
\contentsline {subsection}{\tocsubsection {}{7.2}{3.7.2 什么是模型微调fine tuning}}{106}{subsection.3.7.2}
\contentsline {subsection}{\tocsubsection {}{7.3}{3.7.3 微调时候网络参数是否更新？}}{106}{subsection.3.7.3}
\contentsline {subsection}{\tocsubsection {}{7.4}{3.7.4 fine-tuning 模型的三种状态}}{107}{subsection.3.7.4}
\contentsline {section}{\tocsection {}{8}{3.8 权重偏差初始化}}{107}{section.3.8}
\contentsline {subsection}{\tocsubsection {}{8.1}{3.8.1 全都初始化为 0}}{107}{subsection.3.8.1}
\contentsline {subsection}{\tocsubsection {}{8.2}{3.8.2 全都初始化为同样的值}}{107}{subsection.3.8.2}
\contentsline {subsection}{\tocsubsection {}{8.3}{3.8.3 初始化为小的随机数}}{108}{subsection.3.8.3}
\contentsline {subsection}{\tocsubsection {}{8.4}{3.8.4 用 $ 1/\sqrt n $ 校准方差}}{109}{subsection.3.8.4}
\contentsline {subsection}{\tocsubsection {}{8.5}{3.8.5 稀疏初始化(Sparse Initialazation)}}{109}{subsection.3.8.5}
\contentsline {subsection}{\tocsubsection {}{8.6}{3.8.6 初始化偏差}}{109}{subsection.3.8.6}
\contentsline {section}{\tocsection {}{9}{3.9 学习率}}{109}{section.3.9}
\contentsline {subsection}{\tocsubsection {}{9.1}{3.9.1 学习率的作用}}{109}{subsection.3.9.1}
\contentsline {subsection}{\tocsubsection {}{9.2}{学习率衰减常用参数有哪些}}{110}{table.3.3}
\contentsline {subsection}{\tocsubsection {}{9.3}{分段常数衰减}}{110}{subsection.3.9.3}
\contentsline {subsection}{\tocsubsection {}{9.4}{ 指数衰减}}{110}{subsection.3.9.4}
\contentsline {subsection}{\tocsubsection {}{9.5}{自然指数衰减}}{110}{subsection.3.9.5}
\contentsline {subsection}{\tocsubsection {}{9.6}{ 多项式衰减}}{110}{subsection.3.9.6}
\contentsline {subsection}{\tocsubsection {}{9.7}{ 余弦衰减}}{111}{subsection.3.9.7}
\contentsline {section}{\tocsection {}{10}{ Dropout系列问题}}{111}{section.3.10}
\contentsline {subsection}{\tocsubsection {}{10.1}{为什么要正则化？}}{111}{subsection.3.10.1}
\contentsline {subsection}{\tocsubsection {}{10.2}{为什么正则化有利于预防过拟合？}}{112}{subsection.3.10.2}
\contentsline {subsection}{\tocsubsection {}{10.3}{理解dropout正则化}}{112}{subsection.3.10.3}
\contentsline {subsection}{\tocsubsection {}{10.4}{dropout率的选择}}{112}{subsection.3.10.4}
\contentsline {subsection}{\tocsubsection {}{10.5}{dropout有什么缺点？}}{112}{subsection.3.10.5}
\contentsline {section}{\tocsection {}{11}{深度学习中常用的数据增强方法？}}{113}{section.3.11}
\contentsline {section}{\tocsection {}{12}{如何理解 Internal CovariateShift？}}{113}{section.3.12}
\contentsline {subsection}{\tocsubsection {}{2.2}{4.2.2 模型结构}}{117}{figure.4.3}
\contentsline {subsection}{\tocsubsection {}{2.3}{4.2.3 模型特性}}{118}{subsection.4.2.3}
\contentsline {section}{\tocsection {}{3}{4.3 ZFNet}}{118}{section.4.3}
\contentsline {subsection}{\tocsubsection {}{3.1}{4.3.1 模型介绍}}{118}{subsection.4.3.1}
\contentsline {subsection}{\tocsubsection {}{3.3}{4.3.3 模型特性}}{119}{subsection.4.3.3}
\contentsline {section}{\tocsection {}{4}{4.4 Network in Network}}{119}{section.4.4}
\contentsline {subsection}{\tocsubsection {}{4.1}{4.4.1 模型介绍}}{119}{subsection.4.4.1}
\contentsline {subsection}{\tocsubsection {}{4.2}{4.4.2 模型结构}}{120}{subsection.4.4.2}
\contentsline {subsection}{\tocsubsection {}{5.2}{4.5.2 模型结构}}{121}{figure.4.8}
\contentsline {subsection}{\tocsubsection {}{5.3}{4.5.3 模型特性}}{122}{subsection.4.5.3}
\contentsline {section}{\tocsection {}{6}{4.6 GoogLeNet}}{122}{section.4.6}
\contentsline {subsection}{\tocsubsection {}{6.1}{4.6.1 模型介绍}}{122}{subsection.4.6.1}
\contentsline {subsection}{\tocsubsection {}{6.2}{4.6.2 模型结构}}{123}{subsection.4.6.2}
\contentsline {subsection}{\tocsubsection {}{6.3}{4.6.3 模型特性}}{124}{subsection.4.6.3}
\contentsline {section}{\tocsection {}{7}{Restnet}}{124}{section.4.7}
\contentsline {section}{\tocsection {}{8}{Densenet}}{124}{section.4.8}
\contentsline {section}{\tocsection {}{9}{4.7 为什么现在的CNN模型都是在GoogleNet、VGGNet或者AlexNet上调整的？}}{124}{section.4.9}
\contentsline {chapter}{\tocchapter {Chapter}{5}{卷积神经网络（CNN）}}{129}{chapter.5}
\contentsline {subsection}{\tocsubsection {}{0.1}{5.1 卷积神经网络的组成层}}{129}{subsection.5.0.1}
\contentsline {subsubsection}{\tocsubsubsection {}{0.1.1}{5.1.1 输入层}}{129}{subsubsection.5.0.1.1}
\contentsline {subsubsection}{\tocsubsubsection {}{0.1.2}{5.1.2 卷积层}}{130}{subsubsection.5.0.1.2}
\contentsline {subsubsection}{\tocsubsubsection {}{0.1.3}{5.1.3 激活层}}{130}{subsubsection.5.0.1.3}
\contentsline {subsubsection}{\tocsubsubsection {}{0.1.4}{5.1.4 池化层}}{130}{subsubsection.5.0.1.4}
\contentsline {subsubsection}{\tocsubsubsection {}{0.1.5}{5.1.5 全连接层}}{130}{subsubsection.5.0.1.5}
\contentsline {subsection}{\tocsubsection {}{0.2}{5.2 卷积在图像中有什么直观作用}}{130}{subsection.5.0.2}
\contentsline {subsection}{\tocsubsection {}{0.3}{5.3 卷积层有哪些基本参数？}}{131}{subsection.5.0.3}
\contentsline {subsection}{\tocsubsection {}{0.4}{5.4 卷积核有什么类型？}}{132}{subsection.5.0.4}
\contentsline {subsection}{\tocsubsection {}{0.6}{5.7 有哪些池化方法？}}{134}{subsection.5.0.6}
\contentsline {subsection}{\tocsubsection {}{0.8}{5.9 卷积层和池化层有什么区别？}}{135}{subsection.5.0.8}
\contentsline {subsection}{\tocsubsection {}{0.9}{5.10 卷积核是否一定越大越好？}}{135}{subsection.5.0.9}
\contentsline {subsection}{\tocsubsection {}{0.10}{5.11 每层卷积是否只能用一种尺寸的卷积核？}}{135}{subsection.5.0.10}
\contentsline {subsubsection}{\tocsubsubsection {}{0.14.3}{5.15.3 棋盘效应}}{136}{subsubsection.5.0.14.3}
\contentsline {subsection}{\tocsubsection {}{0.15}{5.16 卷积神经网络的参数设置}}{136}{subsection.5.0.15}
\contentsline {subsection}{\tocsubsection {}{0.16}{5.17 提高卷积神经网络的泛化能力}}{140}{subsection.5.0.16}
\contentsline {subsection}{\tocsubsection {}{0.17}{5.18 卷积神经网络在不同领域的应用}}{148}{subsection.5.0.17}
\contentsline {subsection}{\tocsubsection {}{0.19}{5.20 全连接、局部连接、全卷积与局部卷积}}{149}{subsection.5.0.19}
\contentsline {subsection}{\tocsubsection {}{0.20}{5.21 局部卷积的应用}}{154}{subsection.5.0.20}
\contentsline {subsection}{\tocsubsection {}{0.21}{5.22 NetVLAD池化 （贡献者：熊楚原-中国人民大学）}}{154}{subsection.5.0.21}
\contentsline {chapter}{\tocchapter {Chapter}{6}{循环神经网络(RNN)}}{159}{chapter.6}
\contentsline {section}{\tocsection {}{1}{6.1为什么需要RNN？}}{159}{section.6.1}
\contentsline {section}{\tocsection {}{2}{6.2 图解RNN基本结构}}{159}{section.6.2}
\contentsline {subsection}{\tocsubsection {}{2.1}{6.2.1 基本的单层网络结构}}{159}{subsection.6.2.1}
\contentsline {subsection}{\tocsubsection {}{2.2}{6.2.2 图解经典RNN结构}}{159}{subsection.6.2.2}
\contentsline {subsection}{\tocsubsection {}{2.3}{6.2.3 vector-to-sequence结构}}{160}{subsection.6.2.3}
\contentsline {subsection}{\tocsubsection {}{2.4}{6.2.4 sequence-to-vector结构}}{160}{subsection.6.2.4}
\contentsline {subsection}{\tocsubsection {}{2.5}{6.2.5 Encoder-Decoder结构}}{160}{subsection.6.2.5}
\contentsline {subsection}{\tocsubsection {}{2.6}{以上三种结构各有怎样的应用场景}}{161}{table.6.1}
\contentsline {subsection}{\tocsubsection {}{2.7}{6.2.7 图解RNN中的Attention机制}}{161}{subsection.6.2.7}
\contentsline {section}{\tocsection {}{3}{6.3 RNNs典型特点？}}{161}{section.6.3}
\contentsline {section}{\tocsection {}{4}{6.4 CNN和RNN的区别 ？}}{162}{section.6.4}
\contentsline {section}{\tocsection {}{5}{6.5 RNNs和FNNs有什么区别？}}{162}{section.6.5}
\contentsline {section}{\tocsection {}{6}{6.6 RNNs训练和传统ANN训练异同点？}}{162}{section.6.6}
\contentsline {section}{\tocsection {}{7}{6.7 为什么RNN 训练的时候Loss波动很大}}{163}{section.6.7}
\contentsline {section}{\tocsection {}{8}{6.8 标准RNN前向输出流程}}{163}{section.6.8}
\contentsline {section}{\tocsection {}{9}{6.9 BPTT算法推导}}{163}{section.6.9}
\contentsline {section}{\tocsection {}{10}{6.9 RNN中为什么会出现梯度消失？}}{164}{section.6.10}
\contentsline {section}{\tocsection {}{11}{6.10 如何解决RNN中的梯度消失问题？}}{165}{section.6.11}
\contentsline {section}{\tocsection {}{12}{6.11 LSTM}}{165}{section.6.12}
\contentsline {subsection}{\tocsubsection {}{12.1}{6.11.1 LSTM的产生原因}}{165}{subsection.6.12.1}
\contentsline {subsection}{\tocsubsection {}{12.2}{6.11.2 图解标准RNN和LSTM的区别}}{165}{subsection.6.12.2}
\contentsline {subsection}{\tocsubsection {}{12.3}{6.11.3 LSTM核心思想图解}}{166}{subsection.6.12.3}
\contentsline {subsection}{\tocsubsection {}{12.4}{6.11.4 LSTM流行的变体}}{166}{subsection.6.12.4}
\contentsline {section}{\tocsection {}{13}{6.12 LSTMs与GRUs的区别}}{167}{section.6.13}
\contentsline {section}{\tocsection {}{14}{6.13 RNNs在NLP中典型应用？}}{167}{section.6.14}
\contentsline {section}{\tocsection {}{15}{6.13 常见的RNNs扩展和改进模型}}{167}{section.6.15}
\contentsline {subsection}{\tocsubsection {}{15.1}{6.13.1 Simple RNNs(SRNs)}}{167}{subsection.6.15.1}
\contentsline {subsection}{\tocsubsection {}{15.2}{6.13.2 Bidirectional RNNs}}{168}{subsection.6.15.2}
\contentsline {subsection}{\tocsubsection {}{15.3}{6.13.3 Deep RNNs}}{168}{subsection.6.15.3}
\contentsline {subsection}{\tocsubsection {}{15.4}{6.13.4 Echo State Networks（ESNs）}}{168}{subsection.6.15.4}
\contentsline {subsection}{\tocsubsection {}{15.5}{6.13.4 Gated Recurrent Unit Recurrent Neural Networks}}{168}{subsection.6.15.5}
\contentsline {subsection}{\tocsubsection {}{15.6}{6.13.5 Bidirectional LSTMs}}{169}{subsection.6.15.6}
\contentsline {subsection}{\tocsubsection {}{15.7}{6.13.6 Stacked LSTMs}}{169}{subsection.6.15.7}
\contentsline {subsection}{\tocsubsection {}{15.8}{6.13.7 Clockwork RNNs(CW-RNNs)}}{169}{subsection.6.15.8}
\contentsline {subsection}{\tocsubsection {}{15.9}{6.13.8 CNN-LSTMs}}{170}{subsection.6.15.9}
\contentsline {chapter}{\tocchapter {Chapter}{7}{生成对抗网络}}{173}{chapter.7}
\contentsline {section}{\tocsection {}{1}{7.1 GAN基本概念}}{173}{section.7.1}
\contentsline {subsection}{\tocsubsection {}{1.1}{如何通俗理解GAN？}}{173}{subsection.7.1.1}
\contentsline {subsection}{\tocsubsection {}{1.2}{7.1.2 GAN的形式化表达}}{173}{subsection.7.1.2}
\contentsline {subsection}{\tocsubsection {}{1.3}{7.1.3 GAN的目标函数是什么？}}{173}{subsection.7.1.3}
\contentsline {subsection}{\tocsubsection {}{1.4}{7.1.4 GAN的目标函数和交叉熵有什么区别？}}{174}{subsection.7.1.4}
\contentsline {subsection}{\tocsubsection {}{1.5}{7.1.5 GAN的Loss为什么降不下去？}}{174}{subsection.7.1.5}
\contentsline {subsection}{\tocsubsection {}{1.6}{7.1.6 生成式模型、判别式模型的区别？}}{175}{subsection.7.1.6}
\contentsline {subsection}{\tocsubsection {}{1.7}{7.1.7 什么是mode collapsing?}}{176}{subsection.7.1.7}
\contentsline {subsection}{\tocsubsection {}{1.8}{7.1.8 如何解决mode collapsing？}}{176}{subsection.7.1.8}
\contentsline {section}{\tocsection {}{2}{7.2 GAN的生成能力评价}}{176}{section.7.2}
\contentsline {subsection}{\tocsubsection {}{2.1}{7.2.1 如何客观评价GAN的生成能力？}}{177}{subsection.7.2.1}
\contentsline {subsection}{\tocsubsection {}{2.2}{7.2.2 Inception Score}}{177}{subsection.7.2.2}
\contentsline {subsection}{\tocsubsection {}{2.3}{7.2.3 Mode Score}}{177}{subsection.7.2.3}
\contentsline {subsection}{\tocsubsection {}{2.4}{7.2.4 Kernel MMD (Maximum Mean Discrepancy)}}{177}{subsection.7.2.4}
\contentsline {subsection}{\tocsubsection {}{2.5}{7.2.5 Wasserstein distance}}{178}{subsection.7.2.5}
\contentsline {subsection}{\tocsubsection {}{2.6}{7.2.6 Fréchet Inception Distance (FID)}}{178}{subsection.7.2.6}
\contentsline {subsection}{\tocsubsection {}{2.7}{7.2.7 1-Nearest Neighbor classifier}}{178}{subsection.7.2.7}
\contentsline {subsection}{\tocsubsection {}{2.8}{7.2.8 其他评价方法}}{178}{subsection.7.2.8}
\contentsline {section}{\tocsection {}{3}{7.3 其他常见的生成式模型有哪些？}}{178}{section.7.3}
\contentsline {subsection}{\tocsubsection {}{3.1}{7.3.1 什么是自回归模型：pixelRNN与pixelCNN？}}{178}{subsection.7.3.1}
\contentsline {subsection}{\tocsubsection {}{3.2}{7.3.2 什么是VAE？}}{179}{subsection.7.3.2}
\contentsline {section}{\tocsection {}{4}{7.4 GAN的改进与优化}}{179}{section.7.4}
\contentsline {subsection}{\tocsubsection {}{4.1}{7.4.1 如何生成指定类型的图像------条件GAN}}{179}{subsection.7.4.1}
\contentsline {subsection}{\tocsubsection {}{4.2}{7.4.2 CNN与GAN------DCGAN}}{180}{subsection.7.4.2}
\contentsline {subsection}{\tocsubsection {}{4.3}{7.4.3 如何理解GAN中的输入随机噪声？}}{180}{subsection.7.4.3}
\contentsline {subsection}{\tocsubsection {}{4.4}{7.4.4 GAN为什么容易训练崩溃？}}{180}{subsection.7.4.4}
\contentsline {subsection}{\tocsubsection {}{4.5}{7.4.5 WGAN如何解决训练崩溃问题？}}{181}{subsection.7.4.5}
\contentsline {subsection}{\tocsubsection {}{4.6}{7.4.6 WGAN-GP：带有梯度正则的WGAN}}{181}{subsection.7.4.6}
\contentsline {subsection}{\tocsubsection {}{4.7}{7.4.7 LSGAN}}{181}{subsection.7.4.7}
\contentsline {subsection}{\tocsubsection {}{4.8}{7.4.8 如何尽量避免GAN的训练崩溃问题？}}{182}{subsection.7.4.8}
\contentsline {section}{\tocsection {}{5}{7.3 GAN的应用（图像翻译）}}{182}{section.7.5}
\contentsline {subsection}{\tocsubsection {}{5.1}{7.3.1 什么是图像翻译？}}{182}{subsection.7.5.1}
\contentsline {subsection}{\tocsubsection {}{5.2}{7.3.2 有监督图像翻译：pix2pix}}{183}{subsection.7.5.2}
\contentsline {subsection}{\tocsubsection {}{5.3}{7.3.3 其他图像翻译的tricks}}{183}{subsection.7.5.3}
\contentsline {subsection}{\tocsubsection {}{5.4}{7.3.4 如何生成高分辨率图像和高分辨率视频？}}{183}{subsection.7.5.4}
\contentsline {subsection}{\tocsubsection {}{5.5}{7.3.5 有监督的图像翻译的缺点？}}{184}{subsection.7.5.5}
\contentsline {subsection}{\tocsubsection {}{5.6}{7.3.6 无监督图像翻译：CycleGAN}}{184}{subsection.7.5.6}
\contentsline {subsection}{\tocsubsection {}{5.7}{7.3.7 多领域的无监督图像翻译：StarGAN}}{184}{subsection.7.5.7}
\contentsline {section}{\tocsection {}{6}{7.4 GAN的应用（文本生成）}}{185}{section.7.6}
\contentsline {subsection}{\tocsubsection {}{6.1}{7.4.1 GAN为什么不适合文本任务？}}{185}{subsection.7.6.1}
\contentsline {subsection}{\tocsubsection {}{6.2}{7.4.2 seqGAN用于文本生成}}{185}{subsection.7.6.2}
\contentsline {section}{\tocsection {}{7}{7.5 GAN在其他领域的应用}}{185}{section.7.7}
\contentsline {subsection}{\tocsubsection {}{7.1}{7.5.1 数据增广}}{185}{subsection.7.7.1}
\contentsline {subsection}{\tocsubsection {}{7.2}{7.5.2 图像超分辨与图像补全}}{186}{subsection.7.7.2}
\contentsline {subsection}{\tocsubsection {}{7.3}{7.5.3 语音领域}}{186}{subsection.7.7.3}
\contentsline {subsection}{\tocsubsection {}{2.3}{8.2.3 Faster R-CNN}}{190}{subsection.8.2.3}
\contentsline {subsection}{\tocsubsection {}{2.4}{8.2.4 R-FCN}}{190}{subsection.8.2.4}
\contentsline {subsection}{\tocsubsection {}{2.8}{8.2.8 CBNet}}{191}{subsection.8.2.8}
\contentsline {subsection}{\tocsubsection {}{3.2}{8.3.2 DSSD}}{193}{subsection.8.3.2}
\contentsline {subsection}{\tocsubsection {}{3.5}{8.3.5 YOLO9000}}{194}{subsection.8.3.5}
\contentsline {subsection}{\tocsubsection {}{5.2}{8.5.2 OHEM}}{197}{subsection.8.5.2}
\contentsline {subsection}{\tocsubsection {}{5.3}{8.5.3 NMS：Soft NMS/ Polygon NMS/ Inclined NMS/ ConvNMS/ Yes-Net NMS/ Softer NMS}}{197}{subsection.8.5.3}
\contentsline {subsection}{\tocsubsection {}{5.4}{8.5.4 Multi Scale Training/Testing}}{197}{subsection.8.5.4}
\contentsline {subsection}{\tocsubsection {}{5.5}{8.5.5 建立小物体与context的关系}}{197}{subsection.8.5.5}
\contentsline {section}{\tocsection {}{6}{8.6 目标检测的常用数据集}}{198}{section.8.6}
\contentsline {subsection}{\tocsubsection {}{6.1}{8.6.1 PASCAL VOC}}{198}{subsection.8.6.1}
\contentsline {subsection}{\tocsubsection {}{6.2}{8.6.2 MS COCO}}{198}{subsection.8.6.2}
\contentsline {subsection}{\tocsubsection {}{6.3}{8.6.3 Google Open Image}}{198}{subsection.8.6.3}
\contentsline {subsection}{\tocsubsection {}{6.4}{8.6.4 ImageNet}}{199}{subsection.8.6.4}
\contentsline {subsection}{\tocsubsection {}{6.5}{8.6.5 DOTA}}{199}{subsection.8.6.5}
\contentsline {section}{\tocsection {}{7}{8.7 目标检测常用标注工具}}{199}{section.8.7}
\contentsline {subsection}{\tocsubsection {}{7.1}{8.7.1 LabelImg}}{199}{subsection.8.7.1}
\contentsline {subsection}{\tocsubsection {}{7.2}{8.7.2 labelme}}{199}{subsection.8.7.2}
\contentsline {subsection}{\tocsubsection {}{7.3}{8.7.3 Labelbox}}{199}{subsection.8.7.3}
\contentsline {subsection}{\tocsubsection {}{7.4}{8.7.4 RectLabel}}{200}{subsection.8.7.4}
\contentsline {subsection}{\tocsubsection {}{7.5}{8.7.5 CVAT}}{200}{subsection.8.7.5}
\contentsline {subsection}{\tocsubsection {}{7.6}{8.7.6 VIA}}{200}{subsection.8.7.6}
\contentsline {subsection}{\tocsubsection {}{7.7}{8.7.6 其他标注工具}}{200}{subsection.8.7.7}
\contentsline {section}{\tocsection {}{8}{8.8 目标检测工具和框架（贡献者：北京理工大学--明奇）}}{201}{section.8.8}
\contentsline {section}{\tocsection {}{9}{TODO}}{202}{section.8.9}
\contentsline {subsection}{\tocsubsection {}{3.4}{9.2.4 全连接层和卷积层如何相互转化？}}{205}{subsection.9.3.4}
\contentsline {section}{\tocsection {}{8}{9.7 PSPNet}}{208}{section.9.8}
\contentsline {section}{\tocsection {}{9}{9.8 DeepLab系列}}{209}{section.9.9}
\contentsline {subsection}{\tocsubsection {}{9.1}{9.8.1 DeepLabv1}}{209}{subsection.9.9.1}
\contentsline {subsection}{\tocsubsection {}{9.2}{9.8.2 DeepLabv2}}{209}{subsection.9.9.2}
\contentsline {subsection}{\tocsubsection {}{10.1}{9.9.1 Mask-RCNN 的网络结构示意图}}{210}{subsection.9.10.1}
\contentsline {subsection}{\tocsubsection {}{10.2}{9.9.2 RCNN行人检测框架}}{210}{subsection.9.10.2}
\contentsline {subsection}{\tocsubsection {}{10.3}{9.9.3 Mask-RCNN 技术要点}}{210}{subsection.9.10.3}
\contentsline {subsection}{\tocsubsection {}{11.2}{9.10.2 图像级别标记}}{211}{subsection.9.11.2}
\contentsline {subsection}{\tocsubsection {}{11.3}{9.10.3 DeepLab+bounding box+image-level labels**}}{211}{subsection.9.11.3}
\contentsline {subsection}{\tocsubsection {}{11.5}{9.10.5 弱监督分割最新进展（贡献者：明奇-北京理工大学）}}{212}{subsection.9.11.5}
\contentsline {section}{\tocsection {}{14}{9.13 全景分割（贡献者：北京理工大学--明奇）}}{213}{section.9.14}
\contentsline {subsection}{\tocsubsection {}{3.1}{强化学习和监督式学习的区别：}}{219}{subsection.10.3.1}
\contentsline {subsection}{\tocsubsection {}{3.2}{强化学习和非监督式学习的区别：}}{219}{subsection.10.3.2}
\contentsline {chapter}{\tocchapter {Chapter}{11}{迁移学习}}{227}{chapter.11}
\contentsline {section}{\tocsection {}{1}{迁移学习基础知识}}{227}{section.11.1}
\contentsline {subsection}{\tocsubsection {}{1.1}{什么是迁移学习？}}{227}{subsection.11.1.1}
\contentsline {subsection}{\tocsubsection {}{1.2}{为什么需要迁移学习？}}{227}{subsection.11.1.2}
\contentsline {subsection}{\tocsubsection {}{1.3}{迁移学习的基本问题有哪些？}}{227}{subsection.11.1.3}
\contentsline {subsection}{\tocsubsection {}{1.4}{迁移学习有哪些常用概念？}}{227}{subsection.11.1.4}
\contentsline {subsection}{\tocsubsection {}{1.5}{迁移学习与传统机器学习有什么区别？}}{229}{table.11.1}
\contentsline {subsection}{\tocsubsection {}{1.6}{迁移学习与其他概念的区别？}}{230}{subsection.11.1.6}
\contentsline {subsection}{\tocsubsection {}{1.7}{什么是负迁移？产生负迁移的原因有哪些？}}{230}{subsection.11.1.7}
\contentsline {subsection}{\tocsubsection {}{1.8}{迁移学习的基本思路？}}{230}{subsection.11.1.8}
\contentsline {subsection}{\tocsubsection {}{3.9}{什么是深度网络自适应？}}{231}{subsection.11.3.9}
\contentsline {chapter}{\tocchapter {Chapter}{12}{网络搭建及训练}}{235}{chapter.12}
\contentsline {section}{\tocsection {}{1}{ TensorFlow}}{235}{section.12.1}
\contentsline {section}{\tocsection {}{2}{TensorFlow是什么？}}{235}{section.12.2}
\contentsline {section}{\tocsection {}{3}{TensorFlow的设计理念是什么？}}{235}{section.12.3}
\contentsline {section}{\tocsection {}{4}{TensorFlow特点有哪些？}}{236}{section.12.4}
\contentsline {subsection}{\tocsubsection {}{4.1}{高度的灵活性}}{236}{subsection.12.4.1}
\contentsline {subsection}{\tocsubsection {}{4.2}{真正的可移植性}}{236}{subsection.12.4.2}
\contentsline {subsection}{\tocsubsection {}{5.1}{  整个系统从底层到上层可分为七层：}}{237}{figure.12.1}
\contentsline {section}{\tocsection {}{6}{TensorFlow编程模型是怎样的？}}{237}{section.12.6}
\contentsline {subsection}{\tocsubsection {}{6.1}{构建图}}{237}{subsection.12.6.1}
\contentsline {paragraph}{\tocparagraph {}{}{placeholder}}{238}{section*.7}
\contentsline {paragraph}{\tocparagraph {}{}{2.\nonbreakingspace variable}}{239}{section*.8}
\contentsline {paragraph}{\tocparagraph {}{}{\nonbreakingspace initializer}}{239}{section*.9}
\contentsline {subsection}{\tocsubsection {}{6.2}{启动图}}{239}{subsection.12.6.2}
\contentsline {paragraph}{\tocparagraph {}{}{给图输入数据并获取结果}}{240}{section*.10}
\contentsline {section}{\tocsection {}{7}{如何基于tensorflow搭建VGG16}}{241}{section.12.7}
\contentsline {section}{\tocsection {}{8}{Pytorch}}{242}{section.12.8}
\contentsline {section}{\tocsection {}{9}{ Pytorch是什么？}}{242}{section.12.9}
\contentsline {section}{\tocsection {}{10}{ 为什么选择Pytorch？}}{242}{section.12.10}
\contentsline {subsection}{\tocsubsection {}{10.1}{简洁：}}{242}{subsection.12.10.1}
\contentsline {subsection}{\tocsubsection {}{10.2}{速度：}}{242}{subsection.12.10.2}
\contentsline {subsection}{\tocsubsection {}{10.3}{易用：}}{243}{subsection.12.10.3}
\contentsline {subsection}{\tocsubsection {}{10.4}{活跃的社区：}}{243}{subsection.12.10.4}
\contentsline {section}{\tocsection {}{11}{ PyTorch的架构是怎样的？}}{243}{section.12.11}
\contentsline {section}{\tocsection {}{12}{ Pytorch 与 tensorflow之间的差异在哪里？}}{243}{section.12.12}
\contentsline {section}{\tocsection {}{13}{Pytorch有哪些常用工具包？}}{244}{section.12.13}
\contentsline {section}{\tocsection {}{14}{ Caffe}}{244}{section.12.14}
\contentsline {section}{\tocsection {}{15}{ 什么是 Caffe？}}{244}{section.12.15}
\contentsline {section}{\tocsection {}{16}{Caffe的特点是什么？}}{244}{section.12.16}
\contentsline {section}{\tocsection {}{17}{Caffe的设计思想是怎样的？}}{244}{section.12.17}
\contentsline {section}{\tocsection {}{18}{Caffe架构是怎样的？}}{245}{section.12.18}
\contentsline {subsection}{\tocsubsection {}{18.1}{ SyncedMem}}{245}{subsection.12.18.1}
\contentsline {subsection}{\tocsubsection {}{18.2}{ Blob}}{245}{subsection.12.18.2}
\contentsline {subsection}{\tocsubsection {}{18.3}{ Layer}}{246}{subsection.12.18.3}
\contentsline {subsection}{\tocsubsection {}{18.4}{ Net}}{246}{subsection.12.18.4}
\contentsline {subsection}{\tocsubsection {}{18.5}{ Solver}}{246}{subsection.12.18.5}
\contentsline {subsection}{\tocsubsection {}{18.6}{ Proto}}{246}{subsection.12.18.6}
\contentsline {subsection}{\tocsubsection {}{18.7}{ IO}}{247}{subsection.12.18.7}
\contentsline {section}{\tocsection {}{19}{Caffe的有哪些接口？}}{247}{section.12.19}
\contentsline {subsection}{\tocsubsection {}{19.1}{ Caffe Python接口}}{247}{subsection.12.19.1}
\contentsline {subsection}{\tocsubsection {}{19.2}{ Caffe MATLAB接口}}{247}{subsection.12.19.2}
\contentsline {subsection}{\tocsubsection {}{19.3}{Caffe命令行接口}}{247}{subsection.12.19.3}
\contentsline {paragraph}{\tocparagraph {}{}{caffe train}}{248}{section*.11}
\contentsline {paragraph}{\tocparagraph {}{}{ caffe test}}{248}{section*.12}
\contentsline {paragraph}{\tocparagraph {}{}{ caffe time}}{248}{section*.13}
\contentsline {subsection}{\tocsubsection {}{19.4}{网络搭建有什么原则？}}{248}{subsection.12.19.4}
\contentsline {subsection}{\tocsubsection {}{19.5}{新手原则}}{248}{subsection.12.19.5}
\contentsline {subsection}{\tocsubsection {}{19.6}{深度优先原则。}}{248}{subsection.12.19.6}
\contentsline {subsection}{\tocsubsection {}{19.7}{卷积核size一般为奇数。}}{248}{subsection.12.19.7}
\contentsline {subsection}{\tocsubsection {}{19.8}{卷积核不是越大越好。}}{248}{subsection.12.19.8}
\contentsline {section}{\tocsection {}{20}{有哪些经典的网络模型值得我们去学习的？}}{248}{section.12.20}
\contentsline {section}{\tocsection {}{21}{10.6 网络训练有哪些技巧吗？}}{252}{section.12.21}
\contentsline {subsection}{\tocsubsection {}{21.1}{10.6.1.合适的数据集。}}{252}{subsection.12.21.1}
\contentsline {subsection}{\tocsubsection {}{21.2}{合适的预处理方法}}{252}{subsection.12.21.2}
\contentsline {subsection}{\tocsubsection {}{21.3}{网络的初始化}}{252}{subsection.12.21.3}
\contentsline {subsection}{\tocsubsection {}{21.4}{小规模数据试练}}{252}{subsection.12.21.4}
\contentsline {subsection}{\tocsubsection {}{21.5}{设置合理LearningRate}}{252}{subsection.12.21.5}
\contentsline {subsection}{\tocsubsection {}{21.6}{损失函数}}{252}{subsection.12.21.6}
\contentsline {chapter}{\tocchapter {Chapter}{13}{优化算法}}{257}{chapter.13}
\contentsline {section}{\tocsection {}{1}{如何解决训练样本少的问题}}{257}{section.13.1}
\contentsline {section}{\tocsection {}{2}{深度学习是否能胜任所有数据集?}}{257}{section.13.2}
\contentsline {section}{\tocsection {}{3}{有没有可能找到比已知算法更好的算法?}}{257}{section.13.3}
\contentsline {section}{\tocsection {}{4}{什么是共线性，如何判断和解决共线性问题?}}{258}{section.13.4}
\contentsline {section}{\tocsection {}{5}{权值初始化方法有哪些？}}{258}{section.13.5}
\contentsline {section}{\tocsection {}{6}{如何防止梯度下降陷入局部最优解?}}{259}{section.13.6}
\contentsline {section}{\tocsection {}{7}{为什么需要激活函数？}}{260}{section.13.7}
\contentsline {section}{\tocsection {}{8}{常见的损失函数有哪些?}}{261}{section.13.8}
\contentsline {section}{\tocsection {}{9}{ 如何进行特征选择(feature selection)?}}{262}{section.13.9}
\contentsline {subsection}{\tocsubsection {}{9.1}{特征类型有哪些？}}{262}{subsection.13.9.1}
\contentsline {subsection}{\tocsubsection {}{9.2}{如何考虑特征选择}}{263}{subsection.13.9.2}
\contentsline {subsection}{\tocsubsection {}{9.3}{特征选择方法分类}}{263}{subsection.13.9.3}
\contentsline {subsection}{\tocsubsection {}{9.4}{特征选择目的}}{263}{subsection.13.9.4}
\contentsline {section}{\tocsection {}{10}{梯度消失/梯度爆炸原因，以及解决方法}}{263}{section.13.10}
\contentsline {subsection}{\tocsubsection {}{10.1}{为什么要使用梯度更新规则?}}{263}{subsection.13.10.1}
\contentsline {subsection}{\tocsubsection {}{10.2}{梯度消失/爆炸产生的原因?}}{264}{subsection.13.10.2}
\contentsline {subsection}{\tocsubsection {}{10.3}{梯度消失、爆炸的解决方案}}{265}{subsection.13.10.3}
\contentsline {section}{\tocsection {}{11}{深度学习为什么不用二阶优化？}}{266}{section.13.11}
\contentsline {section}{\tocsection {}{12}{为什么要设置单一数字评估指标，设置指标的意义？}}{266}{section.13.12}
\contentsline {section}{\tocsection {}{13}{训练/验证/测试集的定义及划分}}{266}{section.13.13}
\contentsline {section}{\tocsection {}{14}{什么是TOP5错误率？}}{267}{section.13.14}
\contentsline {section}{\tocsection {}{15}{什么是泛化误差，如何理解方差和偏差？}}{267}{section.13.15}
\contentsline {section}{\tocsection {}{16}{如何提升模型的稳定性？}}{268}{section.13.16}
\contentsline {section}{\tocsection {}{17}{有哪些改善模型的思路}}{268}{section.13.17}
\contentsline {subsection}{\tocsubsection {}{17.1}{数据角度}}{268}{subsection.13.17.1}
\contentsline {subsection}{\tocsubsection {}{17.2}{ 模型角度}}{268}{subsection.13.17.2}
\contentsline {subsection}{\tocsubsection {}{17.3}{调参优化角度}}{268}{subsection.13.17.3}
\contentsline {subsection}{\tocsubsection {}{17.4}{ 训练角度}}{269}{subsection.13.17.4}
\contentsline {section}{\tocsection {}{18}{如何快速构建有效初始模型？}}{269}{section.13.18}
\contentsline {section}{\tocsection {}{19}{如何通过模型重新观察数据？}}{270}{section.13.19}
\contentsline {section}{\tocsection {}{20}{如何解决数据不匹配问题？}}{270}{section.13.20}
\contentsline {subsection}{\tocsubsection {}{20.1}{如何定位数据不匹配?}}{270}{subsection.13.20.1}
\contentsline {subsection}{\tocsubsection {}{20.2}{举例常见几个数据不匹配的场景?}}{270}{subsection.13.20.2}
\contentsline {subsection}{\tocsubsection {}{20.3}{如何解决数据不匹配问题?}}{270}{subsection.13.20.3}
\contentsline {subsection}{\tocsubsection {}{20.4}{如何提高深度学习系统的性能}}{271}{subsection.13.20.4}
\contentsline {section}{\tocsection {}{1}{ 超参数概念}}{275}{section.14.1}
\contentsline {subsection}{\tocsubsection {}{1.1}{什么是超参数，参数和超参数的区别？}}{275}{subsection.14.1.1}
\contentsline {subsection}{\tocsubsection {}{1.2}{神经网络中包含哪些超参数？}}{275}{subsection.14.1.2}
\contentsline {subsection}{\tocsubsection {}{1.3}{为什么要进行超参数调优？}}{275}{subsection.14.1.3}
\contentsline {subsection}{\tocsubsection {}{1.4}{14.2.4 超参数的重要性顺序}}{275}{subsection.14.1.4}
\contentsline {subsection}{\tocsubsection {}{1.5}{14.2.5 部分超参数如何影响模型性能？}}{278}{table.14.1}
\contentsline {subsection}{\tocsubsection {}{1.6}{14.2.6 部分超参数合适的范围}}{279}{table.14.2}
\contentsline {section}{\tocsection {}{2}{14.3 网络训练中的超参调整策略}}{279}{section.14.2}
\contentsline {subsection}{\tocsubsection {}{2.1}{14.3.1 如何调试模型？}}{279}{subsection.14.2.1}
\contentsline {subsection}{\tocsubsection {}{2.2}{14.3.2 为什么要做学习率调整?}}{279}{subsection.14.2.2}
\contentsline {subsection}{\tocsubsection {}{2.4}{14.3.4 极端批样本数量下，如何训练网络？}}{281}{subsection.14.2.4}
\contentsline {section}{\tocsection {}{3}{14.4 合理使用预训练网络}}{281}{section.14.3}
\contentsline {subsection}{\tocsubsection {}{3.1}{14.4.1 什么是微调（fine-tune）}}{281}{subsection.14.3.1}
\contentsline {subsection}{\tocsubsection {}{3.2}{14.4.2 微调有哪些不同方法？}}{282}{subsection.14.3.2}
\contentsline {subsection}{\tocsubsection {}{3.3}{14.4.3 微调先冻结底层，训练顶层的原因？}}{282}{subsection.14.3.3}
\contentsline {subsection}{\tocsubsection {}{3.4}{14.4.4 不同的数据集特性下如何微调？}}{282}{subsection.14.3.4}
\contentsline {subsection}{\tocsubsection {}{3.5}{14.4.4 目标检测中使用预训练模型的优劣？}}{283}{subsection.14.3.5}
\contentsline {subsection}{\tocsubsection {}{3.6}{14.4.5 目标检测中如何从零开始训练(train from scratch)？}}{283}{subsection.14.3.6}
\contentsline {section}{\tocsection {}{4}{14.5 如何改善 GAN 的性能}}{283}{section.14.4}
\contentsline {subsection}{\tocsubsection {}{4.1}{14.6.1 什么是AutoML？}}{284}{subsection.14.4.1}
\contentsline {subsection}{\tocsubsection {}{4.2}{14.6.2 自动化超参数搜索方法有哪些？}}{284}{subsection.14.4.2}
\contentsline {subsection}{\tocsubsection {}{4.3}{14.6.3 什么是神经网络架构搜索（NAS）}}{285}{subsection.14.4.3}
\contentsline {subsection}{\tocsubsection {}{4.5}{14.6.5 网络设计中，为什么卷积核设计尺寸都是奇数}}{286}{subsection.14.4.5}
\contentsline {subsection}{\tocsubsection {}{4.6}{14.6.6 网络设计中，权重共享的形式有哪些，为什么要权重共享}}{286}{subsection.14.4.6}
\contentsline {chapter}{\tocchapter {Chapter}{15}{第十五章 异构计算，GPU和框架选型指南}}{289}{chapter.15}
\contentsline {subsection}{\tocsubsection {}{0.1}{15.1 什么是异构计算？}}{289}{subsection.15.0.1}
\contentsline {subsection}{\tocsubsection {}{0.2}{15.2 什么是GPU？}}{289}{subsection.15.0.2}
\contentsline {subsubsection}{\tocsubsubsection {}{0.5.2}{15.5.2 购买建议}}{290}{subsubsection.15.0.5.2}
\contentsline {subsection}{\tocsubsection {}{0.6}{15.6 软件环境搭建}}{291}{subsection.15.0.6}
\contentsline {subsubsection}{\tocsubsubsection {}{0.6.1}{15.6.1 操作系统选择？}}{291}{subsubsection.15.0.6.1}
\contentsline {subsubsection}{\tocsubsubsection {}{0.6.2}{15.6.2 常用基础软件安装？}}{291}{subsubsection.15.0.6.2}
\contentsline {subsubsection}{\tocsubsubsection {}{0.6.3}{15.6.3 本机安装还是使用docker？}}{292}{subsubsection.15.0.6.3}
\contentsline {subsubsection}{\tocsubsubsection {}{0.6.4}{15.6.4 GPU驱动问题}}{292}{subsubsection.15.0.6.4}
\contentsline {subsection}{\tocsubsection {}{0.7}{15.7 框架选择}}{292}{subsection.15.0.7}
\contentsline {subsubsection}{\tocsubsubsection {}{0.7.1}{15.7.1 主流框架比较}}{292}{subsubsection.15.0.7.1}
\contentsline {subsubsection}{\tocsubsubsection {}{0.7.2}{15.7.2 框架详细信息}}{292}{subsubsection.15.0.7.2}
\contentsline {subsubsection}{\tocsubsubsection {}{0.7.3}{15.7.3 哪些框架对于部署环境友好？}}{295}{subsubsection.15.0.7.3}
\contentsline {subsubsection}{\tocsubsubsection {}{0.7.4}{15.7.4 移动平台的框架如何选择？}}{295}{subsubsection.15.0.7.4}
\contentsline {subsection}{\tocsubsection {}{0.8}{15.8 其他}}{295}{subsection.15.0.8}
\contentsline {subsubsection}{\tocsubsubsection {}{0.8.1}{15.8.1 多GPU环境的配置}}{295}{subsubsection.15.0.8.1}
\contentsline {subsubsection}{\tocsubsubsection {}{0.8.2}{15.8.2 是不是可以分布式训练？}}{295}{subsubsection.15.0.8.2}
\contentsline {subsubsection}{\tocsubsubsection {}{0.8.3}{15.8.3 可以在SPARK环境里训练或者部署模型吗？}}{295}{subsubsection.15.0.8.3}
\contentsline {subsubsection}{\tocsubsubsection {}{0.8.4}{15.8.4 怎么进一步优化性能？}}{295}{subsubsection.15.0.8.4}
\contentsline {subsubsection}{\tocsubsubsection {}{0.8.5}{15.8.5 TPU和GPU的区别？}}{295}{subsubsection.15.0.8.5}
\contentsline {subsubsection}{\tocsubsubsection {}{0.8.6}{15.8.6 未来量子计算对于深度学习等AI技术的影响？}}{295}{subsubsection.15.0.8.6}
\contentsline {subsection}{\tocsubsection {}{0.9}{15.1 GPU购买指南}}{295}{subsection.15.0.9}
\contentsline {subsubsection}{\tocsubsubsection {}{0.9.1}{15.1.1 如何选择GPU}}{296}{subsubsection.15.0.9.1}
\contentsline {subsubsection}{\tocsubsubsection {}{0.9.2}{15.1.2 GPU的主要性能指标}}{296}{subsubsection.15.0.9.2}
\contentsline {subsubsection}{\tocsubsubsection {}{0.9.3}{15.1.3 整机配置}}{296}{subsubsection.15.0.9.3}
\contentsline {subsubsection}{\tocsubsubsection {}{0.9.4}{15.1.4 小结}}{296}{subsubsection.15.0.9.4}
\contentsline {subsection}{\tocsubsection {}{0.10}{15.2 框架选型}}{296}{subsection.15.0.10}
\contentsline {subsubsection}{\tocsubsubsection {}{0.10.1}{15.2.1 常用框架简介}}{296}{subsubsection.15.0.10.1}
\contentsline {subsection}{\tocsubsection {}{0.11}{15.3 模型部署}}{297}{subsection.15.0.11}
\contentsline {chapter}{\tocchapter {Chapter}{16}{第十六章 NLP}}{301}{chapter.16}
\contentsline {section}{\tocsection {}{1}{16.0 NLP 发展史简述}}{301}{section.16.1}
\contentsline {subsection}{\tocsubsection {}{1.1}{第一个浪潮：理性主义}}{301}{subsection.16.1.1}
\contentsline {subsection}{\tocsubsection {}{1.2}{第二波浪潮：经验主义}}{302}{subsection.16.1.2}
\contentsline {subsection}{\tocsubsection {}{1.3}{第三波浪潮：深度学习}}{303}{subsection.16.1.3}
\contentsline {section}{\tocsection {}{2}{16.1 如何理解序列到序列模型？}}{306}{section.16.2}
\contentsline {section}{\tocsection {}{3}{16.2 序列到序列模型有什么限制吗？}}{306}{section.16.3}
\contentsline {section}{\tocsection {}{4}{16.3 如果不采用序列到序列模型，可以考虑用其它模型方法吗？}}{306}{section.16.4}
\contentsline {section}{\tocsection {}{5}{16.4 如何理解词向量？}}{306}{section.16.5}
\contentsline {section}{\tocsection {}{6}{16.5 词向量哪家好？}}{306}{section.16.6}
\contentsline {section}{\tocsection {}{7}{16.6 解释一下注意力机制的原理？}}{306}{section.16.7}
\contentsline {section}{\tocsection {}{8}{16.7 注意力机制是不是适用于所有场景呢？它的鲁棒性如何？}}{306}{section.16.8}
\contentsline {section}{\tocsection {}{9}{16.8 怎么将原有的模型加上注意力机制呢？}}{306}{section.16.9}
\contentsline {section}{\tocsection {}{10}{16.9 通俗地解释一下词法分析是什么？有什么应用场景？}}{306}{section.16.10}
\contentsline {section}{\tocsection {}{11}{16.10 深度学习中的词法分析有哪些常见模型呢？}}{306}{section.16.11}
\contentsline {section}{\tocsection {}{12}{16.11 通俗地解释一下知识图谱是什么？有什么应用场景？}}{306}{section.16.12}
\contentsline {section}{\tocsection {}{13}{16.12 深度学习中的知识图谱有哪些常见模型呢？}}{306}{section.16.13}
\contentsline {section}{\tocsection {}{14}{16.13 深度学习中的机器翻译有哪些常见模型呢？}}{306}{section.16.14}
\contentsline {section}{\tocsection {}{15}{16.14 机器翻译的通俗实现以及部署过程是怎样的呢？}}{306}{section.16.15}
\contentsline {section}{\tocsection {}{16}{16.15 通俗地解释一下文本情感分析是什么？常见的应用场景是？}}{306}{section.16.16}
\contentsline {section}{\tocsection {}{17}{16.16 最常用的情感分析模型是什么呢？如何快速部署呢？}}{306}{section.16.17}
\contentsline {section}{\tocsection {}{18}{16.17 通俗地解释一下问答系统？它涵盖哪些领域？常见的应用场景是？}}{306}{section.16.18}
\contentsline {section}{\tocsection {}{19}{16.18 常见的问答系统模型是什么？如何快速部署呢？}}{306}{section.16.19}
\contentsline {section}{\tocsection {}{20}{16.19 图像文字生成是什么？它的技术原理是什么？}}{306}{section.16.20}
\contentsline {section}{\tocsection {}{21}{16.20 常见的图像文字生成模型是什么？}}{306}{section.16.21}
\contentsline {section}{\tocsection {}{22}{16.21 NLP 的无监督学习发展动态是怎样的？有哪些领域在尝试无监督学习？}}{306}{section.16.22}
\contentsline {section}{\tocsection {}{23}{16.22 NLP 和强化学习的结合方式是怎样的？有哪些方向在尝试强化学习？}}{306}{section.16.23}
\contentsline {section}{\tocsection {}{24}{16.23 NLP 和元学习？元学习如何能够和 NLP 结合起来？}}{306}{section.16.24}
\contentsline {section}{\tocsection {}{25}{16.24 能说一下各自领域最常用且常见的基准模型有哪些吗？}}{306}{section.16.25}
\contentsline {chapter}{\tocchapter {Chapter}{17}{模型压缩及移动端部署}}{309}{chapter.17}
\contentsline {subsection}{\tocsubsection {}{0.1}{模型压缩理解}}{309}{subsection.17.0.1}
\contentsline {subsection}{\tocsubsection {}{0.2}{为什么需要模型压缩和加速？}}{309}{subsection.17.0.2}
\contentsline {subsection}{\tocsubsection {}{0.3}{17.3 模型压缩的必要性及可行性}}{310}{table.17.1}
\contentsline {subsection}{\tocsubsection {}{0.4}{17.4 目前有哪些深度学习模型压缩方法？}}{310}{subsection.17.0.4}
\contentsline {subsubsection}{\tocsubsubsection {}{0.4.1}{17.4.1 前端压缩和后端压缩对比}}{310}{table.17.2}
\contentsline {subsubsection}{\tocsubsubsection {}{0.4.2}{17.4.2 网络剪枝}}{310}{subsubsection.17.0.4.2}
\contentsline {subsubsection}{\tocsubsubsection {}{0.4.5}{17.4.5 前端压缩}}{311}{subsubsection.17.0.4.5}
\contentsline {subsubsection}{\tocsubsubsection {}{0.4.6}{17.4.6 后端压缩}}{311}{subsubsection.17.0.4.6}
\contentsline {subsubsection}{\tocsubsubsection {}{0.4.8}{17.4.7 总体压缩效果评价指标有哪些？}}{313}{subsubsection.17.0.4.8}
\contentsline {subsubsection}{\tocsubsubsection {}{0.4.9}{17.4.8 几种轻量化网络结构对比}}{313}{table.17.12}
\contentsline {subsubsection}{\tocsubsubsection {}{0.4.10}{17.4.9 网络压缩未来研究方向有哪些？}}{313}{subsubsection.17.0.4.10}
\contentsline {subsubsection}{\tocsubsubsection {}{0.5.3}{17.5.3 TensorRT如何优化重构模型？}}{314}{table.17.13}
\contentsline {subsubsection}{\tocsubsubsection {}{0.5.4}{17.5.4 TensorRT加速效果如何？}}{314}{subsubsection.17.0.5.4}
\contentsline {subsection}{\tocsubsection {}{0.6}{17.6 影响神经网络速度的4个因素（再稍微详细一点）}}{315}{subsection.17.0.6}
\contentsline {subsection}{\tocsubsection {}{0.7}{17.7 压缩和加速方法如何选择？}}{315}{subsection.17.0.7}
\contentsline {subsection}{\tocsubsection {}{0.8}{17.8 改变网络结构设计为什么会实现模型压缩、加速？}}{315}{subsection.17.0.8}
\contentsline {subsubsection}{\tocsubsubsection {}{0.8.1}{17.8.1 Group convolution}}{315}{subsubsection.17.0.8.1}
\contentsline {subsubsection}{\tocsubsubsection {}{0.8.2}{17.8.2. Depthwise separable convolution}}{317}{subsubsection.17.0.8.2}
\contentsline {subsubsection}{\tocsubsubsection {}{0.8.3}{17.8.3 输入输出的channel相同时，MAC最小}}{320}{subsubsection.17.0.8.3}
\contentsline {subsubsection}{\tocsubsubsection {}{0.8.4}{17.8.4 减少组卷积的数量}}{321}{subsubsection.17.0.8.4}
\contentsline {subsubsection}{\tocsubsubsection {}{0.8.5}{17.8.5 减少网络碎片化程度(分支数量)}}{321}{subsubsection.17.0.8.5}
\contentsline {subsubsection}{\tocsubsubsection {}{0.8.6}{17.8.7 减少元素级操作}}{322}{subsubsection.17.0.8.6}
\contentsline {subsection}{\tocsubsection {}{0.9}{17.9 常用的轻量级网络有哪些？}}{323}{subsection.17.0.9}
\contentsline {subsubsection}{\tocsubsubsection {}{0.9.1}{17.9.1 SequeezeNet}}{323}{subsubsection.17.0.9.1}
\contentsline {paragraph}{\tocparagraph {}{}{1.3实验结果}}{325}{section*.14}
\contentsline {subsubsection}{\tocsubsubsection {}{0.9.2}{17.9.2 MobileNet}}{325}{subsubsection.17.0.9.2}
\contentsline {paragraph}{\tocparagraph {}{}{2.3 实验结果}}{329}{section*.15}
\contentsline {subsubsection}{\tocsubsubsection {}{0.9.3}{17.9.3 MobileNet-v2}}{329}{subsubsection.17.0.9.3}
\contentsline {paragraph}{\tocparagraph {}{}{3.2 网络架构}}{329}{section*.16}
\contentsline {subsubsection}{\tocsubsubsection {}{0.9.4}{17.9.4 Xception}}{333}{subsubsection.17.0.9.4}
\contentsline {paragraph}{\tocparagraph {}{}{4.2网络架构}}{333}{section*.17}
\contentsline {subsubsection}{\tocsubsubsection {}{0.9.5}{17.9.5 ShuffleNet-v1}}{334}{subsubsection.17.0.9.5}
\contentsline {paragraph}{\tocparagraph {}{}{5.2 网络架构}}{335}{section*.18}
\contentsline {subsubsection}{\tocsubsubsection {}{0.9.6}{17.9.6 ShuffleNet-v2}}{339}{subsubsection.17.0.9.6}
\contentsline {paragraph}{\tocparagraph {}{}{6.2 网络结构}}{339}{section*.19}
\contentsline {paragraph}{\tocparagraph {}{}{6.4 ShuffleNet-v2具有高精度的原因}}{341}{section*.20}
\contentsline {subsection}{\tocsubsection {}{0.10}{17.10 现有移动端开源框架及其特点}}{341}{subsection.17.0.10}
\contentsline {subsubsection}{\tocsubsubsection {}{0.10.1}{17.10.1 NCNN}}{341}{subsubsection.17.0.10.1}
\contentsline {subsubsection}{\tocsubsubsection {}{0.10.3}{17.10.3 Prestissimo}}{343}{subsubsection.17.0.10.3}
\contentsline {subsubsection}{\tocsubsubsection {}{0.10.4}{17.10.4 MDL（mobile-deep-learning）}}{344}{subsubsection.17.0.10.4}
\contentsline {subsubsection}{\tocsubsubsection {}{0.10.5}{17.10.5 Paddle-Mobile}}{345}{subsubsection.17.0.10.5}
\contentsline {subsubsection}{\tocsubsubsection {}{0.10.9}{17.10.9 PocketFlow}}{347}{subsubsection.17.0.10.9}
\contentsline {subsubsection}{\tocsubsubsection {}{0.10.10}{17.10.10 其他几款支持移动端深度学习的开源框架}}{349}{subsubsection.17.0.10.10}
\contentsline {subsubsection}{\tocsubsubsection {}{0.10.11}{17.10.11 MDL、NCNN和 TFLite比较}}{349}{subsubsection.17.0.10.11}
\contentsline {subsection}{\tocsubsection {}{0.11}{17.11 移动端开源框架部署}}{349}{subsection.17.0.11}
\contentsline {subsubsection}{\tocsubsubsection {}{0.11.1}{17.8.1 以NCNN为例}}{349}{subsubsection.17.0.11.1}
\contentsline {subsubsection}{\tocsubsubsection {}{0.11.2}{17.8.2 以QNNPACK为例}}{350}{subsubsection.17.0.11.2}
\contentsline {subsubsection}{\tocsubsubsection {}{0.11.3}{17.8.4 在Android手机上使用MACE实现图像分类}}{350}{subsubsection.17.0.11.3}
\contentsline {subsubsection}{\tocsubsubsection {}{0.11.4}{17.8.3 在Android手机上使用PaddleMobile实现图像分类}}{350}{subsubsection.17.0.11.4}
\contentsline {subsection}{\tocsubsection {}{0.12}{17.9 移动端开源框架部署疑难}}{354}{subsection.17.0.12}
\contentsline {chapter}{\tocchapter {Chapter}{18}{第十八章\_后端架构选型、离线及实时计算}}{357}{chapter.18}
\contentsline {section}{\tocsection {}{1}{18.1 为什么需要分布式计算？}}{357}{section.18.1}
\contentsline {subsection}{\tocsubsection {}{2.4}{18.2.4 Spark MLllib}}{358}{subsection.18.2.4}
\contentsline {subsection}{\tocsubsection {}{2.5}{18.2.5 Ray}}{358}{subsection.18.2.5}
\contentsline {subsection}{\tocsubsection {}{2.6}{18.2.6 Spark stream}}{360}{subsection.18.2.6}
\contentsline {subsection}{\tocsubsection {}{2.7}{18.2.7 Horovod}}{360}{subsection.18.2.7}
\contentsline {subsection}{\tocsubsection {}{2.8}{18.2.8 BigDL}}{362}{subsection.18.2.8}
\contentsline {subsection}{\tocsubsection {}{2.9}{18.2.9 Petastorm}}{362}{subsection.18.2.9}
\contentsline {subsection}{\tocsubsection {}{2.10}{18.2.10 TensorFlowOnSpark}}{363}{subsection.18.2.10}
\contentsline {subsection}{\tocsubsection {}{4.2}{18.4.2 实时流计算过程}}{364}{figure.18.4}
\contentsline {section}{\tocsection {}{5}{18.5 如何进行离线计算？}}{368}{section.18.5}
\contentsline {section}{\tocsection {}{6}{18.6 如何使用分布式框架提高模型训练速度？}}{368}{section.18.6}
\contentsline {section}{\tocsection {}{7}{18.7 深度学习分布式计算框架如何在移动互联网中应用？}}{368}{section.18.7}
\contentsline {section}{\tocsection {}{8}{18.8 如何在个性化推荐中应用深度学习分布式框架？}}{368}{section.18.8}
\contentsline {section}{\tocsection {}{9}{18.9 如何评价个性化推荐系统的效果？}}{368}{section.18.9}
\contentsline {subsection}{\tocsubsection {}{9.1}{18.9.1 准确率与召回率（Precision \& Recall）}}{368}{subsection.18.9.1}
\contentsline {subsection}{\tocsubsection {}{9.4}{18.9.4 平均正确率（Average Precision）}}{369}{subsection.18.9.4}
\contentsline {chapter}{\tocchapter {Chapter}{19}{第十八章 后端架构选型及应用场景}}{373}{chapter.19}
\contentsline {section}{\tocsection {}{1}{18.1 为什么需要分布式计算？}}{373}{section.19.1}
\contentsline {subsection}{\tocsubsection {}{2.4}{18.2.4 Spark MLllib}}{374}{subsection.19.2.4}
\contentsline {subsection}{\tocsubsection {}{2.5}{18.2.5 Ray}}{374}{subsection.19.2.5}
\contentsline {subsection}{\tocsubsection {}{2.7}{18.2.7 Horovod}}{376}{subsection.19.2.7}
\contentsline {subsection}{\tocsubsection {}{2.8}{18.2.8 BigDL}}{377}{subsection.19.2.8}
\contentsline {subsection}{\tocsubsection {}{3.2}{18.3.2 实时流计算过程}}{378}{figure.19.10}
\contentsline {section}{\tocsection {}{4}{18.4 如何进行离线计算？}}{382}{section.19.4}
\contentsline {subsection}{\tocsubsection {}{4.1}{18.4.1 数据采集}}{382}{subsection.19.4.1}
\contentsline {subsection}{\tocsubsection {}{4.2}{18.4.2 数据预处理}}{384}{subsection.19.4.2}
\contentsline {subsection}{\tocsubsection {}{4.3}{18.4.3 数据建模}}{385}{subsection.19.4.3}
\contentsline {subsection}{\tocsubsection {}{4.4}{18.4.4 ETL}}{386}{subsection.19.4.4}
\contentsline {subsection}{\tocsubsection {}{4.5}{18.4.5 数据导出}}{391}{subsection.19.4.5}
\contentsline {subsection}{\tocsubsection {}{4.6}{18.4.6 工作流调度}}{394}{subsection.19.4.6}
\contentsline {section}{\tocsection {}{5}{18.5 如何设计一个人机交互系统？}}{394}{section.19.5}
\contentsline {subsection}{\tocsubsection {}{5.1}{18.5.1 什么是人机交互系统？}}{394}{subsection.19.5.1}
\contentsline {subsection}{\tocsubsection {}{5.5}{18.5.5 什么是指代消解？如何指代消解？}}{395}{subsection.19.5.5}
\contentsline {subsection}{\tocsubsection {}{5.10}{18.5.10 如何评估人机交互系统的效果？}}{398}{subsection.19.5.10}
\contentsline {section}{\tocsection {}{6}{18.6 如何设计个性化推荐系统？}}{398}{section.19.6}
\contentsline {subsection}{\tocsubsection {}{6.1}{18.6.1 什么是个性化推荐系统？}}{398}{subsection.19.6.1}
\contentsline {subsection}{\tocsubsection {}{6.6}{18.6.6 用户画像}}{399}{subsection.19.6.6}
\contentsline {subsection}{\tocsubsection {}{6.7}{18.6.7 GBDT粗排}}{399}{subsection.19.6.7}
\contentsline {subsection}{\tocsubsection {}{6.8}{18.6.8 在线FM精排}}{399}{subsection.19.6.8}
